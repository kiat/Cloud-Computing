{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiat/Cloud-Computing/blob/main/Spark-Example-Social-Media/Colab_SocialMedia_Example_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nor9olN20p0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "32b32c85-f5d9-4b01-ba23-2d817998b118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r            \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,086 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,817 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,389 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,865 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,472 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,288 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,050 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,798 kB]\n",
            "Fetched 36.8 MB in 8s (4,581 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bc058e62d20>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d7a636e18ad8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zc6zAzxEBtsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51846e3e-ef68-46fa-d134-85aab4254712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as func\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "sc2 = SparkSession.builder.getOrCreate()\n",
        "sqlContext = SQLContext(sc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3CjM3406y4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2bNmkjaMYk7r"
      },
      "outputs": [],
      "source": [
        "# Download the data\n",
        "! wget -q https://www.cs.utexas.edu/~kiat/datasets/social-media/person_knows_person.csv\n",
        "! wget -q https://www.cs.utexas.edu/~kiat/datasets/social-media/person_likes_post.csv\n",
        "! wget -q https://www.cs.utexas.edu/~kiat/datasets/social-media/post_hasCreator_person.csv\n",
        "! wget -q https://www.cs.utexas.edu/~kiat/datasets/social-media/comment_hasCreator_person.csv\n",
        "! wget -q https://www.cs.utexas.edu/~kiat/datasets/social-media/comment_replyOf_post.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0qB4iql-uaK",
        "outputId": "f2eb8b1e-20ea-416b-a113-fdc653bddab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 33568\n",
            "drwxr-xr-x 1 root root     4096 Oct 23 16:14 .\n",
            "drwxr-xr-x 1 root root     4096 Oct 23 16:11 ..\n",
            "-rw-r--r-- 1 root root  7398677 Jun 19  2024 comment_hasCreator_person.csv\n",
            "-rw-r--r-- 1 root root  3392677 Jun 19  2024 comment_replyOf_post.csv\n",
            "drwxr-xr-x 4 root root     4096 Oct 21 16:51 .config\n",
            "-rw-r--r-- 1 root root   232246 Jun 19  2024 person_knows_person.csv\n",
            "-rw-r--r-- 1 root root 21372777 Jun 19  2024 person_likes_post.csv\n",
            "-rw-r--r-- 1 root root  1950946 Jun 19  2024 post_hasCreator_person.csv\n",
            "drwxr-xr-x 1 root root     4096 Oct 21 16:52 sample_data\n"
          ]
        }
      ],
      "source": [
        "! ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKSEjiPucGoa",
        "outputId": "66cc3725-b023-4eef-ad3f-4c37f4b519b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h5VEYx0pAgy8"
      },
      "outputs": [],
      "source": [
        "# Set your file path here\n",
        "path=\"file:///content/\"\n",
        "\n",
        "# You have 5 files\n",
        "\n",
        "# comment_hasCreator_person.csv\n",
        "# comment_replyOf_post.csv\n",
        "# person_knows_person.csv\n",
        "# person_likes_post.csv\n",
        "# post_hasCreator_person.csv\n",
        "\n",
        "fileCommentHasCreator= path+\"comment_hasCreator_person.csv\"\n",
        "fileComment_replyOf_post = path+\"comment_replyOf_post.csv\"\n",
        "filePerson_knows_person= path+\"person_knows_person.csv\"\n",
        "filePerson_likes_post = path + \"person_likes_post.csv\"\n",
        "filePost_hasCreator_person = path + \"post_hasCreator_person.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsYcQ5Yc_uN"
      },
      "source": [
        "#Create RDDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rz5WU1Iuccm0"
      },
      "outputs": [],
      "source": [
        "def getRDD(mfile, sc):\n",
        "\t\tlines = sc.textFile(mfile)\n",
        "\t\t# Removing the Header Line\n",
        "\t\tlinesHeader = lines.first()\n",
        "\t\theader = sc.parallelize([linesHeader])\n",
        "\t\tlinesWithOutHeader = lines.subtract(header)\n",
        "\t\tmyRDD = linesWithOutHeader.map(lambda x: x.split('|'))\n",
        "\t\treturn myRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jyaYcn99cSWV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\t# Create RDDs from files\n",
        "\tcommentHasCreator = getRDD(fileCommentHasCreator, sc)\n",
        "\tcomment_replyOf_post = getRDD(fileComment_replyOf_post, sc)\n",
        "\tperson_knows_person = getRDD(filePerson_knows_person, sc)\n",
        "\tperson_likes_post = getRDD(filePerson_likes_post, sc)\n",
        "\tpost_hasCreator_person = getRDD(filePost_hasCreator_person, sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gZJZ01KcUaf",
        "outputId": "3c292558-fd88-4659-a65c-90b4cf4fa589"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['20', '913']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "commentHasCreator.take(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M91Aasfec8BL"
      },
      "source": [
        "# Create Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eHCWjR6rBDfE"
      },
      "outputs": [],
      "source": [
        "commentHasCreatorDD = sqlContext.read.format('csv').options(header='true', inferSchema='true',  sep =\"|\").load(fileCommentHasCreator)\n",
        "comment_replyOf_postDD = sqlContext.read.format('csv').options(header='true', inferSchema='true',  sep =\"|\").load(fileComment_replyOf_post)\n",
        "person_knows_personDD = sqlContext.read.format('csv').options(header='true', inferSchema='true',  sep =\"|\").load(filePerson_knows_person)\n",
        "person_likes_postDD = sqlContext.read.format('csv').options(header='true', inferSchema='true',  sep =\"|\").load(filePerson_likes_post)\n",
        "post_hasCreator_personDD = sqlContext.read.format('csv').options(header='true', inferSchema='true',  sep =\"|\").load(filePost_hasCreator_person)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTMIAdr1dmD2",
        "outputId": "a4922f64-791a-479a-f807-38436cf2447b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|Comment.id|Person.id|\n",
            "+----------+---------+\n",
            "|         0|       74|\n",
            "|        10|      832|\n",
            "|        20|      913|\n",
            "|        30|      457|\n",
            "|        40|      956|\n",
            "|        50|       41|\n",
            "|        60|      453|\n",
            "|        70|      832|\n",
            "|        80|        6|\n",
            "|        90|        6|\n",
            "|       100|      103|\n",
            "|       110|      547|\n",
            "|       120|      962|\n",
            "|       130|       99|\n",
            "|       140|      452|\n",
            "|       150|       99|\n",
            "|       160|        6|\n",
            "|       170|       48|\n",
            "|       180|      941|\n",
            "|       190|       40|\n",
            "+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+-------+\n",
            "|Comment.id|Post.id|\n",
            "+----------+-------+\n",
            "|         0|      0|\n",
            "|        10|      0|\n",
            "|        30|      0|\n",
            "|        70|      0|\n",
            "|       100|     10|\n",
            "|       110|     10|\n",
            "|       140|     10|\n",
            "|       150|     10|\n",
            "|       180|     10|\n",
            "|       240|     20|\n",
            "|       250|     20|\n",
            "|       330|     20|\n",
            "|       340|     30|\n",
            "|       350|     30|\n",
            "|       420|     30|\n",
            "|       470|     40|\n",
            "|       480|     40|\n",
            "|       510|     40|\n",
            "|       560|     40|\n",
            "|       660|     50|\n",
            "+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+----------+\n",
            "|Person.id0|Person.id1|\n",
            "+----------+----------+\n",
            "|        38|       956|\n",
            "|        38|       962|\n",
            "|        38|       941|\n",
            "|        38|        74|\n",
            "|        38|        36|\n",
            "|        38|        53|\n",
            "|        38|        48|\n",
            "|        38|        29|\n",
            "|        38|        46|\n",
            "|        38|        40|\n",
            "|        38|        60|\n",
            "|        38|        31|\n",
            "|        38|        41|\n",
            "|        38|         6|\n",
            "|        38|         4|\n",
            "|        38|       547|\n",
            "|        38|       832|\n",
            "|        38|       129|\n",
            "|        38|       915|\n",
            "|        38|       921|\n",
            "+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------+-------+-------------------+\n",
            "|Person.id|Post.id|       creationDate|\n",
            "+---------+-------+-------------------+\n",
            "|       74|      0|2012-10-15 05:13:41|\n",
            "|       36|      0|2012-10-18 10:51:39|\n",
            "|      417|     10|2012-11-18 11:14:47|\n",
            "|      415|     10|2012-11-20 06:30:22|\n",
            "|      109|     10|2012-11-19 11:03:52|\n",
            "|      119|     10|2012-11-16 09:07:14|\n",
            "|       70|     10|2012-11-19 04:53:43|\n",
            "|       47|     20|2012-10-23 03:32:14|\n",
            "|      378|     20|2012-10-25 01:03:21|\n",
            "|      643|     20|2012-10-18 11:45:28|\n",
            "|      592|     20|2012-10-18 06:02:36|\n",
            "|      576|     20|2012-10-21 02:23:03|\n",
            "|      606|     20|2012-10-24 01:03:00|\n",
            "|      724|     20|2012-10-23 00:17:38|\n",
            "|      672|     20|2012-10-24 04:32:12|\n",
            "|      711|     20|2012-10-22 04:38:54|\n",
            "|      915|     30|2012-06-22 09:10:46|\n",
            "|      921|     30|2012-06-19 03:22:50|\n",
            "|      507|     30|2012-06-23 07:15:14|\n",
            "|      501|     30|2012-06-23 00:34:27|\n",
            "+---------+-------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+---------+\n",
            "|Post.id|Person.id|\n",
            "+-------+---------+\n",
            "|      0|       38|\n",
            "|     10|       38|\n",
            "|     20|       38|\n",
            "|     30|       38|\n",
            "|     40|       38|\n",
            "|     50|       38|\n",
            "|     60|       38|\n",
            "|     70|       38|\n",
            "|     80|       38|\n",
            "|     90|       38|\n",
            "|    100|       38|\n",
            "|    110|       38|\n",
            "|    120|       38|\n",
            "|    130|       38|\n",
            "|    140|       38|\n",
            "|    150|       38|\n",
            "|    160|       38|\n",
            "|    170|       38|\n",
            "|    180|       38|\n",
            "|    190|       38|\n",
            "+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "commentHasCreatorDD.show()\n",
        "comment_replyOf_postDD.show()\n",
        "person_knows_personDD.show()\n",
        "person_likes_postDD.show()\n",
        "post_hasCreator_personDD.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Consider that total user activities count to be the summation of the number of user's posts, comments, likes and having friends. Which top-10 users have the highest activity counts?\n",
        "\n"
      ],
      "metadata": {
        "id": "5w_x8rP_d1wk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XS4aiaZUEABC"
      },
      "outputs": [],
      "source": [
        "\t# Create RDDs from files\n",
        "\t# commentHasCreator\n",
        "\t# comment_replyOf_post\n",
        "\t# person_likes_post\n",
        "\t# post_hasCreator_person\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Which users wrote the top-10 highest active posts? Top-10 posts are posts that have the highest number of comments and likes.\n",
        "\n"
      ],
      "metadata": {
        "id": "CSEvtDzzd_Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cpost_hasCreator_person\n"
      ],
      "metadata": {
        "id": "CfgLXGN8eBtz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Find the top-10 good friends. Two users are considered to be good friends on this social media when they do a lots of likes and comments on each others posts.\n",
        "\n",
        "We would like to find the top-10 of these good friend pairs. Find and print the top-10 good friends based on total number of likes and comments. For each pair of friends you can count up a total score number (sum of all likes and comments), then going over each friendship pair combination, we want to have the top-10.\n",
        "\n"
      ],
      "metadata": {
        "id": "RQwAy93BeB_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "v_WJX8XneDVK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Consider only the users who have at least 20 friends. Who are the two users that have the most number of common friends?\n",
        "Implement it in RDD and Spark Dataframe"
      ],
      "metadata": {
        "id": "jF4T5kFSeDdl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKzeS02leEP_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab-SocialMedia-Example-Spark.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}